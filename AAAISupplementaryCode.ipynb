{"cells":[{"cell_type":"markdown","metadata":{"id":"cHYPtNtY3tVG"},"source":["# MC-CP Supplementary Code"]},{"cell_type":"markdown","metadata":{"id":"jj-NeqR33wLY"},"source":["Dear reviewer,\n","In this notebook you can find all of the supplementary code behind our method, MC-CP. ðŸ™‚"]},{"cell_type":"markdown","metadata":{"id":"u1kvRigs35VT"},"source":["## Misc (Imports, generic functions, etc.)"]},{"cell_type":"markdown","metadata":{"id":"c6nKuZ2H7P5q"},"source":["This section is full of various imports that are needed throughout our tests, as well as functions that are used in most test sections. Unique code/functions that are unique to a specific test can be found under that test.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Mpqki7x3p69"},"outputs":[],"source":["import keras\n","from keras.datasets import mnist, fashion_mnist, cifar10, cifar100, boston_housing\n","from keras.models import Model\n","import numpy as np\n","import pandas as pd\n","import tqdm\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import mean_absolute_error as mae\n","from sklearn.preprocessing import StandardScaler\n","import random\n","from collections import Counter\n","from keras import applications\n","import tensorflow as tf\n","import os\n","from IPython.display import Image, display\n","from keras.utils import load_img\n","from PIL import ImageOps\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8zjA0omV4AQZ"},"outputs":[],"source":["def load_cifar10():\n","  (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","  x_train = x_train.reshape(x_train.shape[0], 32, 32, 3)\n","  x_test = x_test.reshape(x_test.shape[0], 32, 32, 3)\n","  y_train = keras.utils.to_categorical(y_train, 10)\n","  y_test = keras.utils.to_categorical(y_test, 10)\n","  input_shape = (32, 32, 3)\n","  x_train = x_train.astype('float32')\n","  x_test = x_test.astype('float32')\n","  x_train /= 255\n","  x_test /= 255\n","  return x_train, y_train, x_test, y_test, input_shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p_hku6wn4BIV"},"outputs":[],"source":["def load_cifar100():\n","  (x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode=\"fine\")\n","  x_train = x_train.reshape(x_train.shape[0], 32, 32, 3)\n","  x_test = x_test.reshape(x_test.shape[0], 32, 32, 3)\n","  y_train = keras.utils.to_categorical(y_train, 100)\n","  y_test = keras.utils.to_categorical(y_test, 100)\n","  input_shape = (32, 32, 3)\n","  x_train = x_train.astype('float32')\n","  x_test = x_test.astype('float32')\n","  x_train /= 255\n","  x_test /= 255\n","  return x_train, y_train, x_test, y_test, input_shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bYTM0c6Q4B8a"},"outputs":[],"source":["def load_mnist():\n","  (x_train, y_train), (x_test, y_test) = mnist.load_data()\n","  x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n","  x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n","  y_train = keras.utils.to_categorical(y_train, 10)\n","  y_test = keras.utils.to_categorical(y_test, 10)\n","  input_shape = (28, 28, 1)\n","  x_train = x_train.astype('float32')\n","  x_test = x_test.astype('float32')\n","  x_train /= 255\n","  x_test /= 255\n","  return x_train, y_train, x_test, y_test, input_shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g73smOVI4Csn"},"outputs":[],"source":["def load_fashion_mnist():\n","  (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n","  x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n","  x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n","  y_train = keras.utils.to_categorical(y_train, 10)\n","  y_test = keras.utils.to_categorical(y_test, 10)\n","  input_shape = (28, 28, 1)\n","  x_train = x_train.astype('float32')\n","  x_test = x_test.astype('float32')\n","  x_train /= 255\n","  x_test /= 255\n","  return x_train, y_train, x_test, y_test, input_shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9OLgs5EVgSEt"},"outputs":[],"source":["def load_tiny_imagenet():\n","  dataset = load_dataset(\"zh-plus/tiny-imagenet\")\n","  train = dataset['train']\n","  x_train = [x['image'] for x in train]\n","  x_train = [img_to_array(x) for x in x_train]\n","  y_train = [x['label'] for x in train]\n","  test = dataset['valid']\n","  x_test = [x['image'] for x in test]\n","  x_test = [img_to_array(x) for x in x_test]\n","  y_test = [x['label'] for x in test]\n","\n","  culledx_train = [ind for ind, x in enumerate(x_train) if x.shape != (64, 64, 3)]\n","  x_train = [x for x in x_train if x.shape == (64, 64, 3)]\n","  for index in sorted(culledx_train, reverse=True):\n","    del y_train[index]\n","\n","  culledx_test = [ind for ind, x in enumerate(x_test) if x.shape != (64, 64, 3)]\n","  x_test = [x for x in x_test if x.shape == (64, 64, 3)]\n","  for index in sorted(culledx_test, reverse=True):\n","    del y_test[index]\n","\n","  x_train, x_test = np.asarray(x_train), np.asarray(x_test)\n","  y_train, y_test = np.asarray(y_train), np.asarray(y_test)\n","  x_train = x_train.reshape(x_train.shape[0], 64, 64, 3)\n","  x_test = x_test.reshape(x_test.shape[0], 64, 64, 3)\n","  y_train = keras.utils.to_categorical(y_train, 200)\n","  y_test = keras.utils.to_categorical(y_test, 200)\n","  input_shape = (64, 64, 3)\n","  x_train = x_train.astype('float32')\n","  x_test = x_test.astype('float32')\n","  x_train /= 255\n","  x_test /= 255\n","\n","  return x_train, y_train, x_test, y_test, input_shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J2ZLyjiM4Dl5"},"outputs":[],"source":["def load_housing_prices():\n","  (x_train, y_train), (x_test, y_test) = boston_housing.load_data(path=\"boston_housing.npz\", test_split=0.2, seed=64)\n","  input_shape = x_train.shape[1]\n","  x_train = np.asarray(x_train)\n","  y_train = np.asarray(y_train)\n","  x_test = np.asarray(x_test)\n","  y_test = np.asarray(y_test)\n","  n_train = x_train.shape[0]\n","  in_shape = x_train.shape[1]\n","\n","  idx = np.random.permutation(n_train)\n","  n_half = int(np.floor(n_train/2))\n","  idx_train, idx_cal = idx[:n_half], idx[n_half:2*n_half]\n","\n","  scalerX = StandardScaler()\n","  scalerX = scalerX.fit(x_train[idx_train])\n","\n","  x_train = scalerX.transform(x_train)\n","  x_test = scalerX.transform(x_test)\n","\n","  mean_y_train = np.mean(np.abs(y_train[idx_train]))\n","  y_train = np.squeeze(y_train)/mean_y_train\n","  y_test = np.squeeze(y_test)/mean_y_train\n","\n","  return x_train, y_train, x_test, y_test, idx_train, idx_cal, input_shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z59_L9OVgTjG"},"outputs":[],"source":["def load_blog_feedback():\n","  dataset = load_dataset(\"wwydmanski/blog-feedback\")\n","  train = pd.DataFrame(data=dataset['train'])\n","  test = pd.DataFrame(data=dataset['test'])\n","\n","  y_train = train['target']\n","  del train['target']\n","  y_test = test['target']\n","  del test['target']\n","\n","  x_train = np.asarray(train)\n","  y_train = np.asarray(y_train)\n","  x_test = np.asarray(test)\n","  y_test = np.asarray(y_test)\n","  input_shape = x_train.shape[1]\n","\n","  n_train = x_train.shape[0]\n","  idx = np.random.permutation(n_train)\n","  n_half = int(np.floor(n_train/2))\n","  idx_train, idx_cal = idx[:n_half], idx[n_half:2*n_half]\n","\n","  scaler = StandardScaler()\n","  scaler.fit(x_train[idx_train])\n","\n","  x_train = scaler.transform(x_train)\n","  x_test = scaler.transform(x_test)\n","\n","  mean_y_train = np.mean(np.abs(y_train[idx_train]))\n","  y_train = np.squeeze(y_train)/mean_y_train\n","  y_test = np.squeeze(y_test)/mean_y_train\n","\n","  return x_train, x_test, y_train, y_test, input_shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MJYQrK0sgU5W"},"outputs":[],"source":["def load_concrete():\n","  column_names = [\"Cement\", \"Blast Furnace Slag\", \"Fly Ash\", \"Water\", \"Superplasticizer\", \"Coarse Aggregate\",\n","                  \"Fine Aggregate\", \"Age\", \"Concrete compressive strength\"]\n","  data = pd.read_csv('Concrete_Data.csv', names=column_names)\n","  data.drop(index = data.index[0], axis=0, inplace=True)\n","\n","  y = data['Concrete compressive strength'].astype(float)\n","  del data['Concrete compressive strength']\n","  x = data.astype(float)\n","  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n","\n","  x_train = np.asarray(x_train)\n","  y_train = np.asarray(y_train)\n","  x_test = np.asarray(x_test)\n","  y_test = np.asarray(y_test)\n","  input_shape = x_train.shape[1]\n","\n","  n_train = x_train.shape[0]\n","  idx = np.random.permutation(n_train)\n","  n_half = int(np.floor(n_train/2))\n","  idx_train, idx_cal = idx[:n_half], idx[n_half:2*n_half]\n","\n","  scaler = StandardScaler()\n","  scaler.fit(x_train[idx_train])\n","\n","  x_train = scaler.transform(x_train)\n","  x_test = scaler.transform(x_test)\n","\n","  mean_y_train = np.mean(np.abs(y_train[idx_train]))\n","  y_train = np.squeeze(y_train)/mean_y_train\n","  y_test = np.squeeze(y_test)/mean_y_train\n","\n","  return x_train, x_test, y_train, y_test, input_shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3CTXuJI-gZeP"},"outputs":[],"source":["def load_abalone():\n","  # load data\n","  column_names = [\"sex\", \"length\", \"diameter\", \"height\", \"whole weight\",\n","                \"shucked weight\", \"viscera weight\", \"shell weight\", \"rings\"]\n","  data = pd.read_csv('abalone.data.csv', names=column_names)\n","\n","  # change string to boolean\n","  for label in \"MFI\":\n","    data[label] = data[\"sex\"] == label\n","  del data[\"sex\"]\n","\n","  y = data.rings.values.astype(float)\n","  del data['rings']\n","  x = data.values.astype(float)\n","\n","  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n","  x_train = np.asarray(x_train)\n","  y_train = np.asarray(y_train)\n","  x_test = np.asarray(x_test)\n","  y_test = np.asarray(y_test)\n","  input_shape = x_train.shape[1]\n","\n","\n","  n_train = x_train.shape[0]\n","  idx = np.random.permutation(n_train)\n","  n_half = int(np.floor(n_train/2))\n","  idx_train, idx_cal = idx[:n_half], idx[n_half:2*n_half]\n","\n","  scaler = StandardScaler()\n","  scaler.fit(x_train[idx_train])\n","\n","  x_train = scaler.transform(x_train)\n","  x_test = scaler.transform(x_test)\n","\n","  mean_y_train = np.mean(np.abs(y_train[idx_train]))\n","  y_train = np.squeeze(y_train)/mean_y_train\n","  y_test = np.squeeze(y_test)/mean_y_train\n","\n","  return x_train, x_test, y_train, y_test, input_shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mPu9Rz464FvP"},"outputs":[],"source":["def dropout_layer(input, percent, montecarlo):\n","  if montecarlo:\n","    return keras.layers.Dropout(percent)(input, training=True)\n","  else:\n","    return keras.layers.Dropout(percent)(input)\n","\n","def cnn_model(montecarlo, activation, input_shape, output_dims):\n","  input_layer = keras.layers.Input(input_shape)\n","  layer1A = keras.layers.Conv2D(32, (3, 3), activation=activation)(input_layer)\n","  pooling1 = keras.layers.MaxPooling2D((2, 2))(layer1A)\n","  dropout1 = dropout_layer(pooling1, 0.5, montecarlo)\n","\n","  layer1B = keras.layers.Conv2D(64, (3, 3), activation=activation)(dropout1)\n","  pooling2 = keras.layers.MaxPooling2D((2, 2))(layer1B)\n","  dropout2 = dropout_layer(pooling2, 0.5, montecarlo)\n","\n","  flatten_layer = keras.layers.Flatten()(dropout2)\n","  dense1 = keras.layers.Dense(128, activation=activation)(flatten_layer)\n","  output_layer = keras.layers.Dense(output_dims, activation='softmax')(dense1)\n","\n","  model = Model(inputs=input_layer, outputs=output_layer)\n","  model.compile(loss=keras.losses.categorical_crossentropy,\n","                optimizer=keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n","                metrics=['accuracy'])\n","  return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3OXkVdhe4LUc"},"outputs":[],"source":["\"\"\"\n","Our dynamic MC method\n","Params:\n","  x_test -> a testing dataset to produce predictions on\n","  model -> a model to predict with\n","  patience -> how many forward passes to wait when all classes are lower than\n","  the min_delta threshold\n","  min_delta -> the threshold a class how to be lower than to be considered stable\n","  max_mc -> the maximum number of forward passes if the classes never converge\n","\n","Returns:\n","  A set of predictions\n","\"\"\"\n","def dynamic_mc_predict(x_test, model, patience, min_delta, max_mc):\n","  montecarlo_predictions = []\n","  var_diffs = []\n","  for data in tqdm.tqdm(x_test):\n","    current_patience_count = 0\n","    prev_variance = []\n","    predictions = []\n","    while True:\n","      prediction = model.predict(np.expand_dims(data, axis=0), verbose=0)\n","      predictions.append(prediction)\n","      variance = np.asarray(predictions).std(axis=0)\n","      if len(predictions) != 1:\n","        var_diff = abs(np.subtract(prev_variance, variance))\n","        var_diffs.append(var_diff)\n","        if np.all(var_diff <= min_delta) == True:\n","          current_patience_count +=1\n","        else:\n","          current_patience_count = 0\n","      if current_patience_count > patience or len(predictions) == max_mc:\n","        break\n","      prev_variance = variance\n","    predictions = np.squeeze(predictions)\n","    montecarlo_predictions.append(np.asarray(predictions).mean(axis=0))\n","  return montecarlo_predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LQrxla9Gry7N"},"outputs":[],"source":["\"\"\"\n","Only difference here is we format the predictions into the final array to work nicely with a quantile regressor\n","\"\"\"\n","def dynamic_mc_predict_reg(x_test, model, patience, min_delta, max_mc):\n","  montecarlo_predictions = []\n","  var_diffs = []\n","  for data in tqdm.tqdm(x_test):\n","    current_patience_count = 0\n","    prev_variance = []\n","    predictions = []\n","    while True:\n","      prediction = model.predict(np.expand_dims(data, axis=0), verbose=0)\n","      predictions.append(prediction)\n","      variance = np.array(predictions).std(axis=0)\n","      if len(predictions) != 1:\n","        var_diff = abs(np.subtract(prev_variance, variance))\n","        var_diffs.append(var_diff)\n","        if np.all(var_diff <= min_delta) == True:\n","          current_patience_count +=1\n","        else:\n","          current_patience_count = 0\n","      if current_patience_count > patience or len(predictions) == max_mc:\n","        break\n","      prev_variance = variance\n","    predictions = np.asarray(predictions).mean(axis=0)\n","    predictions = np.reshape(predictions, predictions.shape[0:2])\n","    montecarlo_predictions.append(predictions)\n","  montecarlo_predictions = np.asarray(montecarlo_predictions)\n","  return montecarlo_predictions"]},{"cell_type":"markdown","metadata":{"id":"QGXy_nJKp-p-"},"source":["## Test Dynamic MC Once"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"js2RA6y5qXgM"},"outputs":[],"source":["def dynamic_mc(x_train, y_train, x_test, y_test, output_dims):\n","  model = cnn_model(montecarlo=True, activation='relu', input_shape=input_shape, output_dims=output_dims)\n","  history = model.fit(x_train, y_train, batch_size=128, epochs=10, verbose=1)\n","\n","  # dynamic mc\n","  patience = 10\n","  min_delta = 5e-4\n","  max_mc = 1000\n","  montecarlo_predictions = []\n","  var_diffs = []\n","  for image in tqdm.tqdm(x_test):\n","    current_patience_count = 0\n","    prev_variance = []\n","    predictions = []\n","    while True:\n","      prediction = model.predict(np.expand_dims(image, axis=0), verbose=0)\n","      predictions.append(prediction)\n","      variance = np.array(predictions).std(axis=0)\n","      if len(predictions) != 1:\n","        var_diff = abs(np.subtract(prev_variance, variance))\n","        var_diffs.append(var_diff)\n","        if np.all(var_diff <= min_delta) == True:\n","          current_patience_count +=1\n","        else:\n","          current_patience_count = 0\n","      if current_patience_count > patience or len(predictions) == max_mc:\n","        break\n","      prev_variance = variance\n","    montecarlo_predictions.append(np.array(predictions).mean(axis=0))\n","  return var_diffs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"wp5BfS1Bj4-v","outputId":"d9c326a9-6779-411b-bd5b-448bfe2271e2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170498071/170498071 [==============================] - 5s 0us/step\n","ship\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# load dataset\n","x_train, y_train, x_test, y_test, input_shape = load_cifar10()\n","# convert to readable class names\n","class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n","y_test_new = np.array([np.argmax(y, axis=None, out=None) for y in y_test])\n","\n","# show example image and its corresponding label\n","plt.imshow(x_test[1])\n","true_label = int(y_test_new[1])\n","print(class_names[true_label])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"lxILQ942qC39","outputId":"f824b9ea-a7a1-42c6-9fd1-0c68719fc69b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","391/391 [==============================] - 17s 5ms/step - loss: 1.9997 - accuracy: 0.2574\n","Epoch 2/10\n","391/391 [==============================] - 2s 5ms/step - loss: 1.6146 - accuracy: 0.4131\n","Epoch 3/10\n","391/391 [==============================] - 2s 4ms/step - loss: 1.4613 - accuracy: 0.4742\n","Epoch 4/10\n","391/391 [==============================] - 2s 6ms/step - loss: 1.3758 - accuracy: 0.5073\n","Epoch 5/10\n","391/391 [==============================] - 2s 5ms/step - loss: 1.3195 - accuracy: 0.5272\n","Epoch 6/10\n","391/391 [==============================] - 2s 5ms/step - loss: 1.2588 - accuracy: 0.5505\n","Epoch 7/10\n","391/391 [==============================] - 2s 5ms/step - loss: 1.2202 - accuracy: 0.5644\n","Epoch 8/10\n","391/391 [==============================] - 2s 5ms/step - loss: 1.1813 - accuracy: 0.5809\n","Epoch 9/10\n","391/391 [==============================] - 2s 5ms/step - loss: 1.1593 - accuracy: 0.5893\n","Epoch 10/10\n","391/391 [==============================] - 2s 5ms/step - loss: 1.1267 - accuracy: 0.5991\n"]},{"name":"stderr","output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.10s/it]\n"]}],"source":["var_diff = dynamic_mc(x_train, y_train, x_test[1:2], y_test[1:2], output_dims=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"dUx1PJZ_qdJa"},"outputs":[],"source":["class0_diff = [x[0][0] for x in var_diff]\n","class1_diff = [x[0][1] for x in var_diff]\n","class2_diff = [x[0][2] for x in var_diff]\n","class3_diff = [x[0][3] for x in var_diff]\n","class4_diff = [x[0][4] for x in var_diff]\n","class5_diff = [x[0][5] for x in var_diff]\n","class6_diff = [x[0][6] for x in var_diff]\n","class7_diff = [x[0][7] for x in var_diff]\n","class8_diff = [x[0][8] for x in var_diff]\n","class9_diff = [x[0][9] for x in var_diff]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xFTRT2_kqd1d"},"outputs":[],"source":["x = list(range(0, len(var_diff)))\n","plt.plot(x, class0_diff, label='Airplane')\n","plt.plot(x, class1_diff, label='Automobile')\n","plt.plot(x, class2_diff, label='Bird')\n","plt.plot(x, class3_diff, label='Cat')\n","plt.plot(x, class4_diff, label='Deer')\n","plt.plot(x, class5_diff, label='Dog')\n","plt.plot(x, class6_diff, label='Frog')\n","plt.plot(x, class7_diff, label='Horse')\n","plt.plot(x, class8_diff, label='Ship')\n","plt.plot(x, class9_diff, label='Truck')\n","\n","plt.axhline(y=5e-4, color='r', label=\"Delta\", linestyle='--')\n","plt.ylabel(\"Difference in Variance\")\n","plt.xlabel(\"Ensemble No.\")\n","plt.legend()"]},{"cell_type":"markdown","metadata":{"id":"d5Va7RznmrZc"},"source":["## Test Dynamic MC Once for Regression"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ozLwitdOm3n_"},"outputs":[],"source":["class MultiQuantileLoss(tf.keras.losses.Loss):\n","\n","    def __init__(self, quantiles:list, **kwargs):\n","        super(MultiQuantileLoss, self).__init__(**kwargs)\n","\n","        self.quantiles = quantiles\n","\n","    def call(self, y_true, y_pred):\n","\n","        # get quantile value\n","        q_id = int(y_pred.name.split(\"/\")[1][1:])\n","        q = self.quantiles[q_id]\n","\n","        # minimize quantile error\n","        q_error = tf.subtract(y_true, y_pred)\n","        q_loss = tf.reduce_mean(tf.maximum(q*q_error, (q-1)*q_error), axis=-1)\n","        return q_loss\n","\n","def build_mqnn(quantiles:list, training_x_values:np.ndarray, internal_nodes:list = [32, 32], montecarlo=False,\n","               model_name:str = \"mqnn\", optimizer=None, input_normalization:bool = True):\n","    input_dim = training_x_values.shape[1]\n","    output_dim = len(quantiles)\n","\n","    # define normalizer\n","    normalizer = tf.keras.layers.Normalization()\n","    normalizer.adapt(training_x_values)\n","\n","    # build model's node structure\n","    inputs = keras.layers.Input(shape=input_dim)\n","    mdl = normalizer(inputs)\n","    for n_nodes in internal_nodes:\n","        mdl = keras.layers.Dense(n_nodes, activation='relu')(mdl)\n","        mdl = keras.layers.Dropout(0.25)(mdl, training=montecarlo)\n","    outputs = [keras.layers.Dense(1, activation='linear', name=\"q%d\" % q_i)(mdl) for q_i in range(output_dim)]\n","    del input_dim, output_dim, mdl, normalizer\n","\n","    # define optimizer and loss functions\n","    optm_func = tf.optimizers.Adam(learning_rate=0.001) if optimizer is None else optimizer\n","    loss_func = MultiQuantileLoss(quantiles=quantiles)\n","\n","    # build and compile model\n","    model = tf.keras.models.Model(inputs=inputs, outputs=outputs, name=model_name)\n","    model.compile(optimizer=optm_func, loss=loss_func, metrics=['mae'])\n","\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-EQdGfHQm8QJ"},"outputs":[],"source":["def dynamic_mc(x_train, y_train, x_test, y_test):\n","  quantiles = [0.05, 0.95]\n","  model = build_mqnn(quantiles, x_train, [128, 128], montecarlo=True)\n","  history = model.fit(x_train, y_train, epochs=100, batch_size=32, verbose=1)\n","\n","  # dynamic mc\n","  patience = 10\n","  min_delta = 5e-4\n","  max_mc = 1000\n","  montecarlo_predictions = []\n","  var_diffs = []\n","  for dp in tqdm.tqdm(x_test):\n","    current_patience_count = 0\n","    prev_variance = []\n","    predictions = []\n","    while True:\n","      prediction = model.predict(dp, verbose=0)\n","      predictions.append(prediction)\n","      variance = np.array(predictions).std(axis=0)\n","      if len(predictions) != 1:\n","        var_diff = abs(np.subtract(prev_variance, variance))\n","        var_diffs.append(var_diff)\n","        if np.all(var_diff <= min_delta) == True:\n","          current_patience_count +=1\n","        else:\n","          current_patience_count = 0\n","      if current_patience_count > patience or len(predictions) == max_mc:\n","        break\n","      prev_variance = variance\n","    montecarlo_predictions.append(np.array(predictions).mean(axis=0))\n","  return var_diffs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SXc5I2QfnPDH"},"outputs":[],"source":["# load dataset\n","x_train, y_train, x_test, y_test, idx_train, idx_cal, input_shape = load_housing_prices()\n","\n","# show example dp and its corresponding true value\n","print(x_test[0])\n","print(y_test[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vW38fUA-nfBf"},"outputs":[],"source":["var_diff = dynamic_mc(x_train, y_train, x_test[:1], y_test[:1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uxpHz75ynrmi"},"outputs":[],"source":["quantup_diff = [x[0][0][0] for x in var_diff]\n","quantlow_diff = [x[1][0][0] for x in var_diff]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gMQ8-GuwoYOT"},"outputs":[],"source":["x = list(range(0, len(var_diff)))\n","plt.plot(x, quantup_diff, label='95%')\n","plt.plot(x, quantlow_diff, label='5%')\n","\n","\n","plt.axhline(y=5e-4, color='r', label=\"Delta\", linestyle='--')\n","plt.ylabel(\"Difference in Variance\")\n","plt.xlabel(\"Ensemble No.\")\n","plt.legend()"]},{"cell_type":"markdown","metadata":{"id":"MtrGAGzR58ZI"},"source":["## Produce test errors"]},{"cell_type":"markdown","metadata":{"id":"v2RV0UfV7gzt"},"source":["This section reproduces the table that showcases the test errors for each method on each dataset"]},{"cell_type":"markdown","metadata":{"id":"MQU2tvVR6CBv"},"source":["### Functions"]},{"cell_type":"markdown","metadata":{"id":"4XMtDOKK7muZ"},"source":["Here are a set of unique functions that are only needed in the test section."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eYhATBOq6E_e"},"outputs":[],"source":["def test_error_baseline(iterations, x_train, y_train, x_test, y_test, output_dims):\n","  test_errors = []\n","  for n in range(iterations):\n","    model = cnn_model(montecarlo=False, activation='relu', input_shape=input_shape, output_dims=output_dims)\n","    history = model.fit(x_train, y_train, batch_size=128, epochs=10, verbose=1)\n","    score = model.evaluate(x_test, y_test, verbose=0)\n","    test_accuracy = score[1]\n","    test_error = 1 - test_accuracy\n","    test_errors.append(test_error)\n","  print(\"Test error: {:2f}, +/-{:2f}\".format(np.mean(test_errors), np.std(test_errors)))\n","  return test_errors"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Llly2Sr76QGk"},"outputs":[],"source":["def test_error_mc(iterations, x_train, y_train, x_test, y_test, output_dims):\n","  test_errors = []\n","  for n in range(iterations):\n","    model = cnn_model(montecarlo=True, activation='relu', input_shape=input_shape, output_dims=output_dims)\n","    history = model.fit(x_train, y_train, batch_size=128, epochs=10, verbose=1)\n","    montecarlo_predictions = []\n","    for i in tqdm.tqdm(range(1000)):\n","      prediction = model.predict(x_test, batch_size=1000, verbose=0)\n","      montecarlo_predictions.append(prediction)\n","\n","    # predictions\n","    acc = 0\n","    for idx in tqdm.tqdm(range(len(x_test))):\n","      softmaxes = np.array([p[idx] for p in montecarlo_predictions])\n","      prediction = softmaxes.mean(axis=0).argmax()\n","      true_label = np.where(y_test[idx])[0]\n","\n","      if prediction == true_label:\n","        acc += 1\n","\n","    test_accuracy = acc / len(x_test)\n","    test_error = 1 - test_accuracy\n","    test_errors.append(test_error)\n","  print(\"Test error: {:2f}, +/-{:2f}\".format(np.mean(test_errors), np.std(test_errors)))\n","  return test_errors"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1_dIY00_6Skh"},"outputs":[],"source":["def test_error_naive(iterations, x_train, y_train, x_test, y_test, output_dims):\n","  test_errors = []\n","  for n in range(iterations):\n","    model = cnn_model(montecarlo=False, activation='relu', input_shape=input_shape, output_dims=output_dims)\n","    history = model.fit(x_train, y_train, batch_size=128, epochs=10, verbose=1)\n","    predictions = model.predict(x_test, batch_size=1000)\n","\n","    # calibration\n","    n = 2500\n","    alpha = 0.05\n","    y_test_new = np.array([np.argmax(y, axis=None, out=None) for y in y_test])\n","\n","    idx = np.array([1] * n + [0] * (predictions.shape[0] - n)) > 0\n","    np.random.shuffle(idx)\n","    cal_softmax, val_softmax = predictions[idx, :], predictions[~idx, :]\n","    cal_labels, val_labels = y_test_new[idx], y_test_new[~idx]\n","\n","    cal_scores = 1 - cal_softmax[np.arange(n), cal_labels]\n","\n","    q_level = np.ceil((n + 1) * (1 - alpha)) / n\n","    q_hat = np.quantile(cal_scores, q_level, method=\"higher\")\n","    pred_sets = val_softmax >= (1 - q_hat)\n","\n","    # predictions\n","    acc = 0\n","    for idx in range(len(val_softmax)):\n","      softmax = val_softmax[idx]\n","      preds = softmax > 1 - q_hat\n","      label_set = np.where(preds)[0]\n","      true_label = np.where(val_labels[idx])[0]\n","\n","      if true_label in label_set:\n","        acc += 1\n","\n","    test_accuracy = acc / len(x_test)\n","    test_error = 1 - test_accuracy\n","    test_errors.append(test_error)\n","  print(\"Test error: {:2f}, +/-{:2f}\".format(np.mean(test_errors), np.std(test_errors)))\n","  return test_errors"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vvvU2PYD6T0A"},"outputs":[],"source":["def test_error_raps(iterations, x_train, y_train, x_test, y_test, output_dims):\n","  test_errors = []\n","  for n in range(iterations):\n","    model = cnn_model(montecarlo=False, activation='relu', input_shape=input_shape, output_dims=output_dims)\n","    history = model.fit(x_train, y_train, batch_size=128, epochs=10, verbose=1)\n","    predictions = model.predict(x_test, batch_size=1000)\n","    print(predictions.shape)\n","\n","    # calibration\n","    n = 2500\n","    alpha = 0.05\n","    y_test_new = np.array([np.argmax(y, axis=None, out=None) for y in y_test])\n","    lam_reg = 0.01\n","    k_reg = 5\n","    disallow_zero_sets = False\n","    rand = False\n","    reg_vec = np.array(k_reg * [0,] + (predictions.shape[1] - k_reg) * [lam_reg,])[None,:]\n","\n","    idx = np.array([1] * n + [0] * (predictions.shape[0] - n)) > 0\n","    np.random.shuffle(idx)\n","    cal_softmax, val_softmax = predictions[idx, :], predictions[~idx, :]\n","    cal_labels, val_labels = y_test_new[idx], y_test_new[~idx]\n","\n","    cal_pi = cal_softmax.argsort(1)[:,::-1]\n","    cal_srt = np.take_along_axis(cal_softmax, cal_pi, axis=1)\n","    cal_srt_reg = cal_srt + reg_vec\n","    cal_L = np.where(cal_pi == cal_labels[:, None])[1]\n","    cal_scores = cal_srt_reg.cumsum(axis=1)[np.arange(n), cal_L] - np.random.rand(n) * cal_srt_reg[np.arange(n), cal_L]\n","\n","    q_level = np.ceil((n + 1) * (1 - alpha)) / n\n","    q_hat = np.quantile(cal_scores, q_level, method=\"higher\")\n","\n","    # predictions\n","    acc = 0\n","    for idx in range(len(val_softmax)):\n","      softmax = val_softmax[idx]\n","      _pi = np.argsort(softmax)[::-1]\n","      _srt = np.take_along_axis(softmax, _pi, axis=0)\n","      _srt_reg = _srt + reg_vec.squeeze()\n","      _srt_reg_cumsum = _srt_reg.cumsum()\n","      _ind = (_srt_reg_cumsum - np.random.rand() * _srt_reg) <= q_hat if rand else _srt_reg_cumsum - _srt_reg <= q_hat\n","      if disallow_zero_sets: _ind[0] = True\n","      pred_set = np.take_along_axis(_ind, _pi.argsort(), axis=0)\n","      label_set = np.where(pred_set)[0]\n","      true_label = np.where(val_labels[idx])[0]\n","\n","      if true_label in label_set:\n","        acc += 1\n","\n","    test_accuracy = acc / len(x_test)\n","    test_error = 1 - test_accuracy\n","    test_errors.append(test_error)\n","  print(\"Test error: {:2f}, +/-{:2f}\".format(np.mean(test_errors), np.std(test_errors)))\n","  return test_errors"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lM0iJQTu6UxK"},"outputs":[],"source":["def test_error_mcraps(iterations, x_train, y_train, x_test, y_test, output_dims):\n","  test_errors = []\n","  for n in range(iterations):\n","    model = cnn_model(montecarlo=True, activation='relu', input_shape=input_shape, output_dims=output_dims)\n","    history = model.fit(x_train, y_train, batch_size=128, epochs=10, verbose=1)\n","\n","    montecarlo_predictions = np.asarray(dynamic_mc_predict(x_test, model, 10, 5e-4, 1000))\n","\n","    # calibration\n","    n = 2500\n","    alpha = 0.05\n","    y_test_new = np.array([np.argmax(y, axis=None, out=None) for y in y_test])\n","    lam_reg = 0.01\n","    k_reg = 5\n","    disallow_zero_sets = False\n","    rand = False\n","    reg_vec = np.array(k_reg * [0,] + (montecarlo_predictions.shape[1] - k_reg) * [lam_reg,])[None,:]\n","\n","    idx = np.array([1] * n + [0] * (montecarlo_predictions.shape[0] - n)) > 0\n","    np.random.shuffle(idx)\n","    cal_softmax, val_softmax = montecarlo_predictions[idx, :], montecarlo_predictions[~idx, :]\n","    cal_labels, val_labels = y_test_new[idx], y_test_new[~idx]\n","\n","    cal_pi = cal_softmax.argsort(1)[:,::-1]\n","    cal_srt = np.take_along_axis(cal_softmax, cal_pi, axis=1)\n","    cal_srt_reg = cal_srt + reg_vec\n","    cal_L = np.where(cal_pi == cal_labels[:, None])[1]\n","    cal_scores = cal_srt_reg.cumsum(axis=1)[np.arange(n), cal_L] - np.random.rand(n) * cal_srt_reg[np.arange(n), cal_L]\n","\n","    q_level = np.ceil((n + 1) * (1 - alpha)) / n\n","    q_hat = np.quantile(cal_scores, q_level, method=\"higher\")\n","\n","    # predictions\n","    acc = 0\n","    for idx in range(len(val_softmax)):\n","      _softmax = val_softmax[idx]\n","      _pi = np.argsort(_softmax)[::-1]\n","      _srt = np.take_along_axis(_softmax, _pi, axis=0)\n","      _srt_reg = _srt + reg_vec.squeeze()\n","      _srt_reg_cumsum = _srt_reg.cumsum()\n","      _ind = (_srt_reg_cumsum - np.random.rand() * _srt_reg) <= q_hat if rand else _srt_reg_cumsum - _srt_reg <= q_hat\n","      if disallow_zero_sets: _ind[0] = True\n","      pred_set = np.take_along_axis(_ind, _pi.argsort(), axis=0)\n","      label_set = np.where(pred_set)[0]\n","      true_label = np.where(val_labels[idx])[0]\n","\n","      if true_label in label_set:\n","        acc += 1\n","\n","    test_accuracy = acc / len(x_test)\n","    test_error = 1 - test_accuracy\n","    test_errors.append(test_error)\n","  print(\"Test error: {:2f}, +/-{:2f}\".format(np.mean(test_errors), np.std(test_errors)))\n","  return test_errors"]},{"cell_type":"markdown","metadata":{"id":"H4ooBX1j6Dg0"},"source":["### Tests"]},{"cell_type":"markdown","metadata":{"id":"2lw7WMF47rbs"},"source":["Here are the test outputs for each dataset, as well as some plots when needed."]},{"cell_type":"markdown","metadata":{"id":"N1j59z3u634b"},"source":["#### CIFAR-10"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"usBpvts85_EF"},"outputs":[],"source":["x_train, y_train, x_test, y_test, input_shape = load_cifar10()\n","reg_test_error = test_error_baseline(5, x_train, y_train, x_test, y_test, output_dims=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AsfXIBlg69jZ"},"outputs":[],"source":["x_train, y_train, x_test, y_test, input_shape = load_cifar10()\n","mc_test_error = test_error_mc(5, x_train, y_train, x_test, y_test, output_dims=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G-yDBnSi7AUw"},"outputs":[],"source":["x_train, y_train, x_test, y_test, input_shape = load_cifar10()\n","naive_test_error = test_error_naive(5, x_train, y_train, x_test, y_test, output_dims=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IYSahd-Q7Bgs"},"outputs":[],"source":["x_train, y_train, x_test, y_test, input_shape = load_cifar10()\n","raps_test_error = test_error_raps(1, x_train, y_train, x_test, y_test, output_dims=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":381},"executionInfo":{"elapsed":15612,"status":"error","timestamp":1691494525742,"user":{"displayName":"Daniel Bethell","userId":"00777257039334201804"},"user_tz":-60},"id":"DEHZdVeq7CqZ","outputId":"a7bea817-d882-4f58-8e97-41d3490759b8"},"outputs":[{"name":"stdout","output_type":"stream","text":["391/391 [==============================] - 3s 5ms/step - loss: 1.9635 - accuracy: 0.2766\n"]},{"name":"stderr","output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.86it/s]\n"]},{"ename":"ValueError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-771fc83c0904>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_cifar10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmcraps_test_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_error_mcraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-25-d05f3508d473>\u001b[0m in \u001b[0;36mtest_error_mcraps\u001b[0;34m(iterations, x_train, y_train, x_test, y_test, output_dims)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mq_level\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mq_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcal_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"higher\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mquantile\u001b[0;34m(*args, **kwargs)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mquantile\u001b[0;34m(a, q, axis, out, overwrite_input, method, keepdims, interpolation)\u001b[0m\n\u001b[1;32m   4368\u001b[0m     \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4369\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_quantile_is_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4370\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Quantiles must be in the range [0, 1]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4371\u001b[0m     return _quantile_unchecked(\n\u001b[1;32m   4372\u001b[0m         a, q, axis, out, overwrite_input, method, keepdims)\n","\u001b[0;31mValueError\u001b[0m: Quantiles must be in the range [0, 1]"]}],"source":["x_train, y_train, x_test, y_test, input_shape = load_cifar10()\n","mcraps_test_error = test_error_mcraps(1, x_train, y_train, x_test[:20], y_test[:20], output_dims=10)"]},{"cell_type":"markdown","metadata":{"id":"pNe7sNpD7GCz"},"source":["#### CIFAR-10 Boxplot\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V_t00dR57H_t"},"outputs":[],"source":["a1 = [i * 100 for i in reg_test_error]\n","a2 = [i * 100 for i in mc_test_error]\n","a3 = [i * 100 for i in naive_test_error]\n","a4 = [i * 100 for i in raps_test_error]\n","a5 = [i * 100 for i in mcraps_test_error]\n","data = [a3, a4, a5]\n","\n","labels = ['Naive', 'RAPS', 'MC-CP']\n","\n","fig, ax = plt.subplots()\n","bp = ax.boxplot(data, labels=labels, patch_artist = True,\n","                medianprops = dict(color = \"black\"), vert=False)\n","\n","bp['boxes'][0].set_facecolor('salmon')\n","bp['boxes'][1].set_facecolor('gold')\n","bp['boxes'][2].set_facecolor('limegreen')\n","\n","ax.set_xlabel(\"Test Error %\")\n","ax.set_title(\"CIFAR10 Mean Test Error\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PG5eauia7L2L"},"outputs":[],"source":["a1 = [i * 100 for i in reg_test_error]\n","a2 = [i * 100 for i in mc_test_error]\n","a3 = [i * 100 for i in naive_test_error]\n","a4 = [i * 100 for i in raps_test_error]\n","a5 = [i * 100 for i in mcraps_test_error]\n","data = [a1, a2, a3, a4, a5]\n","\n","labels = ['Baseline', 'MC', 'Naive', 'RAPS', 'MC-CP']\n","\n","fig, ax = plt.subplots()\n","ax.boxplot(data, labels=labels, vert=False)\n","ax.set_ylabel(\"Test Error %\")\n","ax.set_title(\"CIFAR10 Mean Test Error\")"]},{"cell_type":"markdown","metadata":{"id":"_wnkdiZJqre0"},"source":["## Deep Quantile Regressor"]},{"cell_type":"markdown","metadata":{"id":"6maIYaKCtF1C"},"source":["Here are the various functions and tests for the regression section of our paper."]},{"cell_type":"markdown","metadata":{"id":"P_0weiAHqu2b"},"source":["### Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"80ddqnT-q22g"},"outputs":[],"source":["class MultiQuantileLoss(tf.keras.losses.Loss):\n","    def __init__(self, quantiles:list, **kwargs):\n","        super(MultiQuantileLoss, self).__init__(**kwargs)\n","\n","        self.quantiles = quantiles\n","\n","    def call(self, y_true, y_pred):\n","\n","        # get quantile value\n","        q_id = int(y_pred.name.split(\"/\")[1][1:])\n","        q = self.quantiles[q_id]\n","\n","        # minimize quantile error\n","        q_error = tf.subtract(y_true, y_pred)\n","        q_loss = tf.reduce_mean(tf.maximum(q*q_error, (q-1)*q_error), axis=-1)\n","        return q_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YO6XX1A0quRx"},"outputs":[],"source":["def build_mqnn(quantiles:list, training_x_values:np.ndarray, internal_nodes:list = [32, 32], montecarlo=False,\n","               model_name:str = \"mqnn\", optimizer=None, input_normalization:bool = True):\n","\n","    input_dim = training_x_values.shape[1]\n","    output_dim = len(quantiles)\n","\n","    # define normalizer\n","    normalizer = tf.keras.layers.Normalization()\n","    normalizer.adapt(training_x_values)\n","\n","    # build model's node structure\n","    inputs = keras.layers.Input(shape=input_dim)\n","    mdl = normalizer(inputs)\n","    for i, n_nodes in enumerate(internal_nodes):\n","        mdl = keras.layers.Dense(n_nodes, activation='relu')(mdl)\n","        if i != (len(internal_nodes) - 1):\n","          mdl = keras.layers.Dropout(0.1)(mdl, training=montecarlo)\n","    outputs = [keras.layers.Dense(1, activation='linear', name=\"q%d\" % q_i)(mdl) for q_i in range(output_dim)]\n","    del input_dim, output_dim, mdl, normalizer\n","\n","    # define optimizer and loss functions\n","    optm_func = tf.optimizers.Adam(learning_rate=0.001) if optimizer is None else optimizer\n","    loss_func = MultiQuantileLoss(quantiles=quantiles)\n","\n","    # build and compile model\n","    model = tf.keras.models.Model(inputs=inputs, outputs=outputs, name=model_name)\n","    model.compile(optimizer=optm_func, loss=loss_func, metrics=['mae'])\n","\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G-RXNox0q5oZ"},"outputs":[],"source":["def regression_test_mae_regular(iterations, x_train, y_train, x_test, y_test):\n","  test_maes = []\n","  quantiles = [0.05, 0.95]\n","  for n in range(iterations):\n","    model = build_mqnn(quantiles, x_train, [128, 128], False)\n","    history = model.fit(x_train, y_train, epochs=100, batch_size=32, verbose=0)\n","    prediction = model.predict(x_test, batch_size=1000, verbose=0)\n","\n","    upper_preds = []\n","    lower_preds = []\n","    # predictions\n","    for idx in tqdm.tqdm(range(len(x_test))):\n","      upper_pred = prediction[1][idx]\n","      lower_pred = prediction[0][idx]\n","      true_label = y_test[idx]\n","\n","      upper_preds.append(upper_pred)\n","      lower_preds.append(lower_pred)\n","\n","    upper_mae = mae(y_test, upper_preds)\n","    lower_mae = mae(y_test, lower_preds)\n","    full_mae = upper_mae + lower_mae\n","    test_maes.append(full_mae)\n","\n","  print(\"Test MAE: {:2f}, +/-{:2f}\".format(np.mean(test_maes), np.std(test_maes)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u7PcyL1Nq6vQ"},"outputs":[],"source":["def regression_test_mae_mc(iterations, x_train, y_train, x_test, y_test):\n","  test_maes = []\n","  quantiles = [0.05, 0.95]\n","  for n in range(iterations):\n","    model = build_mqnn(quantiles, x_train, [128, 128], True)\n","    history = model.fit(x_train, y_train, epochs=100, batch_size=32, verbose=0)\n","    montecarlo_predictions = []\n","    for i in tqdm.tqdm(range(500)):\n","      prediction = model.predict(x_test, batch_size=1000, verbose=0)\n","      prediction = np.asarray(prediction)\n","      prediction = np.reshape(prediction, prediction.shape[0:2])\n","      montecarlo_predictions.append(prediction)\n","\n","    upper_preds = []\n","    lower_preds = []\n","    # predictions\n","    for idx in tqdm.tqdm(range(len(x_test))):\n","      pred_mean = np.mean(montecarlo_predictions, axis=0)\n","      upper_pred = pred_mean[1][idx]\n","      lower_pred = pred_mean[0][idx]\n","      true_label = y_test[idx]\n","\n","      upper_preds.append(upper_pred)\n","      lower_preds.append(lower_pred)\n","\n","    upper_mae = mae(y_test, upper_preds)\n","    lower_mae = mae(y_test, lower_preds)\n","    full_mae = upper_mae + lower_mae\n","    test_maes.append(full_mae)\n","  print(\"Test MAE: {:2f}, +/-{:2f}\".format(np.mean(test_maes), np.std(test_maes)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XehYdO-3q7oO"},"outputs":[],"source":["def regression_test_mae_cqr(iterations, x_train, y_train, x_test, y_test):\n","  test_maes = []\n","  quantiles = [0.05, 0.95]\n","  uncal_cov = []\n","  cal_cov = []\n","  for n in range(iterations):\n","    model = build_mqnn(quantiles, x_train, [128, 128], False)\n","    history = model.fit(x_train, y_train, epochs=100, batch_size=32, verbose=0)\n","    prediction = np.squeeze(np.asarray(model.predict(x_test, batch_size=1000, verbose=0)))\n","\n","    # calibration\n","    n = 10\n","    alpha = 0.1\n","\n","    idx = np.array([1] * n + [0] * (len(y_test) - n)) > 0\n","    np.random.shuffle(idx)\n","    cal_labels, val_labels = y_test[idx], y_test[~idx]\n","    cal_upper, val_upper = prediction[1][idx], prediction[1][~idx]\n","    cal_lower, val_lower = prediction[0][idx], prediction[0][~idx]\n","\n","    cal_scores = np.maximum(cal_labels-cal_upper, cal_lower-cal_labels)\n","    qhat = np.quantile(cal_scores, np.ceil((n+1)*(1-alpha))/n, method='higher')\n","\n","    prediction_sets = [val_lower - qhat, val_upper + qhat]\n","\n","    # coverage\n","    prediction_sets_uncalibrated = [val_lower, val_upper]\n","    empirical_coverage_uncalibrated = ((val_labels >= prediction_sets_uncalibrated[0]) & (val_labels <= prediction_sets_uncalibrated[1])).mean()\n","    uncal_cov.append(empirical_coverage_uncalibrated)\n","    empirical_coverage = ((val_labels >= prediction_sets[0]) & (val_labels <= prediction_sets[1])).mean()\n","    cal_cov.append(empirical_coverage)\n","\n","    upper_preds = []\n","    lower_preds = []\n","    # predictions\n","    for idx in tqdm.tqdm(range(len(val_lower))):\n","      upper_pred = prediction_sets[1][idx]\n","      lower_pred = prediction_sets[0][idx]\n","      true_label = val_labels[idx]\n","\n","      upper_preds.append(upper_pred)\n","      lower_preds.append(lower_pred)\n","\n","    upper_mae = mae(val_labels, upper_preds)\n","    lower_mae = mae(val_labels, lower_preds)\n","    full_mae = upper_mae + lower_mae\n","    test_maes.append(full_mae)\n","\n","  print(\"Test MAE: {:2f}, +/-{:2f}\".format(np.mean(test_maes), np.std(test_maes)))\n","  print(\"The empirical coverage before calibration is: {:2f}, +/-{:2f}\".format(np.mean(uncal_cov), np.std(uncal_cov)))\n","  print(\"The empirical coverage after calibration is: {:2f}, +/-{:2f}\".format(np.mean(cal_cov), np.std(cal_cov)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9yx0Nw9iq9F8"},"outputs":[],"source":["def regression_test_mae_mccqr(iterations, x_train, y_train, x_test, y_test):\n","  test_maes = []\n","  quantiles = [0.05, 0.95]\n","  uncal_cov = []\n","  cal_cov = []\n","  for n in range(iterations):\n","    model = build_mqnn(quantiles, x_train, [128, 128], True)\n","    history = model.fit(x_train, y_train, epochs=100, batch_size=32, verbose=0)\n","\n","    montecarlo_predictions = dynamic_mc_predict_reg(x_test, model, 10, 5e-4, 1000)\n","\n","    # calibration\n","    n = 10\n","    alpha = 0.1\n","\n","    idx = np.array([1] * n + [0] * (len(y_test) - n)) > 0\n","    np.random.shuffle(idx)\n","    cal_labels, val_labels = y_test[idx], y_test[~idx]\n","    cal_upper, val_upper = montecarlo_predictions[:,1][idx], montecarlo_predictions[:,1][~idx]\n","    cal_lower, val_lower = montecarlo_predictions[:,0][idx], montecarlo_predictions[:,0][~idx]\n","\n","    cal_scores = np.maximum(cal_labels-cal_upper, cal_lower-cal_labels)\n","    qhat = np.quantile(cal_scores, np.ceil((n+1)*(1-alpha))/n, method='higher')\n","\n","    prediction_sets = [val_lower - qhat, val_upper + qhat]\n","\n","    # coverage\n","    prediction_sets_uncalibrated = [val_lower, val_upper]\n","    empirical_coverage_uncalibrated = ((val_labels >= prediction_sets_uncalibrated[0]) & (val_labels <= prediction_sets_uncalibrated[1])).mean()\n","    uncal_cov.append(empirical_coverage_uncalibrated)\n","    empirical_coverage = ((val_labels >= prediction_sets[0]) & (val_labels <= prediction_sets[1])).mean()\n","    cal_cov.append(empirical_coverage)\n","\n","    upper_preds = []\n","    lower_preds = []\n","    # predictions\n","    for idx in tqdm.tqdm(range(len(val_lower))):\n","      upper_pred = prediction_sets[1][idx]\n","      lower_pred = prediction_sets[0][idx]\n","      true_label = val_labels[idx]\n","\n","      upper_preds.append(upper_pred)\n","      lower_preds.append(lower_pred)\n","\n","    upper_mae = mae(val_labels, upper_preds)\n","    lower_mae = mae(val_labels, lower_preds)\n","    full_mae = upper_mae + lower_mae\n","    test_maes.append(full_mae)\n","\n","  print(\"Test MAE: {:2f}, +/-{:2f}\".format(np.mean(test_maes), np.std(test_maes)))\n","  print(\"The empirical coverage before calibration is: {:2f}, +/-{:2f}\".format(np.mean(uncal_cov), np.std(uncal_cov)))\n","  print(\"The empirical coverage after calibration is: {:2f}, +/-{:2f}\".format(np.mean(cal_cov), np.std(cal_cov)))"]},{"cell_type":"markdown","metadata":{"id":"ARE3RkJtqxOK"},"source":["### Tests"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6IkMjIEMqupM"},"outputs":[],"source":["x_train, y_train, x_test, y_test, idx_train, idx_cal, input_shape = load_housing_prices()\n","regression_test_mae_regular(1, x_train, y_train, x_test, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rWOuJ7Bbr9z2"},"outputs":[],"source":["x_train, y_train, x_test, y_test, idx_train, idx_cal, input_shape = load_housing_prices()\n","regression_test_mae_mc(1, x_train, y_train, x_test, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VoFWRi9lr-c8"},"outputs":[],"source":["x_train, y_train, x_test, y_test, idx_train, idx_cal, input_shape = load_housing_prices()\n","regression_test_mae_cqr(1, x_train, y_train, x_test, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vzwZydYIr_ED"},"outputs":[],"source":["x_train, y_train, x_test, y_test, idx_train, idx_cal, input_shape = load_housing_prices()\n","regression_test_mae_mccqr(1, x_train, y_train, x_test, y_test)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["u1kvRigs35VT","QGXy_nJKp-p-","MtrGAGzR58ZI","pNe7sNpD7GCz"],"provenance":[],"authorship_tag":"ABX9TyNc0s/zIRa/p/8R8lWU7J7G"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}